{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Car_eval_pre-final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the initial classes and libraries"
      ],
      "metadata": {
        "id": "VIOOXsKqvCQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGkIriYIDfX1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ISm3qZGWDkMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a54be59-5f72-4345-9ec5-b1f69f5edf88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pre-process"
      ],
      "metadata": {
        "id": "77HoA5T5EIe-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the file from google drive"
      ],
      "metadata": {
        "id": "kDGJllzzEuN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cars_data.csv')\n",
        "df.shape\n",
        "df = df.sample(frac=1) #randomizing the order of data to eliminate any patterns"
      ],
      "metadata": {
        "id": "bNbAf9ctENKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show first 20 values"
      ],
      "metadata": {
        "id": "c8ZvfuC1E2bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(20)"
      ],
      "metadata": {
        "id": "Nkyba_a0EqKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing string data into numbers "
      ],
      "metadata": {
        "id": "Xr7YExGNFQ6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df:\n",
        "    print(df[col].unique())"
      ],
      "metadata": {
        "id": "982UYNkYpbUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['class_values'] = df['class_values'].replace({'unacc':0, 'acc':1, 'good':2, 'vgood':3})\n",
        "\n",
        "df['buying '] = df['buying '].replace({'low':0, 'med':1, 'high':2, 'vhigh':3})\n",
        "\n",
        "df['maint'] = df['maint'].replace({'low':0, 'med':1, 'high':2, 'vhigh':3})\n",
        "\n",
        "df['doors'] = df['doors'].replace({'2':0, '3':1, '4':2, '5more':3})\n",
        "\n",
        "df['persons'] = df['persons'].replace({'2':0, '4':1, 'more':2})\n",
        "\n",
        "df['lug_boots'] = df['lug_boots'].replace({'small':0, 'med':1, 'big':2})\n",
        "\n",
        "df['safety'] = df['safety'].replace({'low':0, 'med':1, 'high':2})"
      ],
      "metadata": {
        "id": "3adCTtZlEqhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist()"
      ],
      "metadata": {
        "id": "UbrTlm3VHpDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the class values to show dicrepancy of the classes"
      ],
      "metadata": {
        "id": "OcbjIIL0ZYJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df:\n",
        "    print(df[col].unique())"
      ],
      "metadata": {
        "id": "zOBkE5VMo2lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist((df.class_values))"
      ],
      "metadata": {
        "id": "qsAgYULVY4Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assinging train and test data"
      ],
      "metadata": {
        "id": "T2zgAWcHFVSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting samples and labels"
      ],
      "metadata": {
        "id": "A6HlvFMTGRoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = df.iloc[:, 0:6]\n",
        "labels = df.iloc[:, 6]"
      ],
      "metadata": {
        "id": "fkHVScDYGQ6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding the labels"
      ],
      "metadata": {
        "id": "HuwunFvAvWIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "labels = lb.fit_transform(labels)"
      ],
      "metadata": {
        "id": "flSfSO6UqEUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the samples"
      ],
      "metadata": {
        "id": "X-OlCcrtvYWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "sc.fit(samples)\n",
        "samples = sc.transform(samples)"
      ],
      "metadata": {
        "id": "MnKrfU4UqFLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting train and test data"
      ],
      "metadata": {
        "id": "nypQsiWzGsYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_samples, test_samples, train_labels, test_labels = train_test_split(samples,labels, test_size = 0.20, random_state = 1)"
      ],
      "metadata": {
        "id": "xHKEQpDKF5UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of train samples"
      ],
      "metadata": {
        "id": "puaDGmLQG9S5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples.shape"
      ],
      "metadata": {
        "id": "0lOSVKZSGylK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of train labels"
      ],
      "metadata": {
        "id": "1d1N1CIuHIjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "metadata": {
        "id": "0Plk4N_PFhD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of test samples"
      ],
      "metadata": {
        "id": "p1IcdwTeHURx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples.shape"
      ],
      "metadata": {
        "id": "wjo3Z6wkHKYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of test lables"
      ],
      "metadata": {
        "id": "rPN9_z59HV4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.shape"
      ],
      "metadata": {
        "id": "2EBToaVvHMr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use GPU for computing (optional)"
      ],
      "metadata": {
        "id": "H1QPYea0MHvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WARNING !**\n",
        "USE ONLY IF YOUR INSTANCE SUPPORTS GPU USAGE\n",
        "\n"
      ],
      "metadata": {
        "id": "n3feoIJqMQq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Num GPU\", len(physical_devices))\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "metadata": {
        "id": "1Ub2ot20MPtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting functions"
      ],
      "metadata": {
        "id": "63Ew6bCtIvPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotacc(history,epochs): #function to plot training accuracy\n",
        "  loss_train = history.history['accuracy']\n",
        "  epochs = range(1,epochs+1)\n",
        "  plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
        "  plt.title('Training accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "SurZ9rzQI1w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotloss(history,epochs): #function to plot training loss\n",
        "  loss_train = history.history['loss']\n",
        "  epochs = range(1,epochs+1)\n",
        "  plt.plot(epochs, loss_train, 'r', label='Training loss')\n",
        "  plt.title('Training loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "yiX3eKCVI8km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotlosswval(history, epochs): #function to plot training loss against validation loss\n",
        "  loss_train = history.history['loss']\n",
        "  loss_val = history.history['val_loss']\n",
        "  epochs = range(1,epochs+1)\n",
        "  plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "  plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "  plt.title('Training and Validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Pu1IIEOZI-Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotaccwval(history,epochs): #function to plot training accuracy against validation accuracy \n",
        "  loss_train = history.history['accuracy']\n",
        "  loss_val = history.history['val_accuracy']\n",
        "  epochs = range(1,epochs+1)\n",
        "  plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
        "  plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
        "  plt.title('Training and Validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "PzdMFKbUI_YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras Sequential Model"
      ],
      "metadata": {
        "id": "RBW9ekwjJGxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout, Conv3D\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Nadam\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "syqVmRILI_9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model to be used in 4 fold cross valitation"
      ],
      "metadata": {
        "id": "jVnTjgd8JpGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " model = keras.Sequential(\n",
        "      [\n",
        "          layers.Dense(30, input_dim=6, kernel_initializer='uniform', activation='relu', kernel_regularizer= tf.keras.regularizers.L2(0.5),bias_regularizer= tf.keras.regularizers.L2(0.9)),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Dense(60, kernel_initializer='uniform', activation='relu', kernel_constraint=tf.keras.constraints.MinMaxNorm(min_value=0.9, max_value=2, axis=0)),\n",
        "          layers.Dropout(0.2),\n",
        "          layers.Dense(10, kernel_initializer='uniform', activation='relu', kernel_constraint=tf.keras.constraints.MinMaxNorm(min_value=1.3, max_value=1.8, axis=0)),\n",
        "          layers.Dropout(0.1),\n",
        "          layers.Dense(1, kernel_initializer='uniform', activation='relu'),\n",
        "\n",
        "          \n",
        "         \n",
        "      ]\n",
        "  )"
      ],
      "metadata": {
        "id": "O-7bPzmJJYPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of the model to be used"
      ],
      "metadata": {
        "id": "OzYdmzdhKfSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "qI8mNGrTKd63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing the number of epochs"
      ],
      "metadata": {
        "id": "fktxgv3zJwwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 600"
      ],
      "metadata": {
        "id": "bz3wsfQ6Je7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declaring the optimiser"
      ],
      "metadata": {
        "id": "bJzZHVSbJ0Na"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model"
      ],
      "metadata": {
        "id": "DINFNDZDJ3B9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iivkiT8FXUaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_samples, train_labels, epochs=600, batch_size=128, shuffle = True)\n",
        "scores = model.evaluate(test_samples, test_labels)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "id": "zROQ-lONXfFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the model"
      ],
      "metadata": {
        "id": "IJyC6QePJ6BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=train_samples, y=train_labels, batch_size=500, epochs=epochs, validation_data=(test_samples, test_labels), shuffle=True, verbose=1)"
      ],
      "metadata": {
        "id": "kydSru0zJl7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model with a different method"
      ],
      "metadata": {
        "id": "VHaXq5lwtcT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_samples, test_labels)\n",
        "#\n",
        "# Print the test accuracy\n",
        "#\n",
        "print('Test Accuracy: ', test_acc, '\\nTest Loss: ', test_loss)"
      ],
      "metadata": {
        "id": "bgPxSQvHrPOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results of the model with basic validation"
      ],
      "metadata": {
        "id": "u6SwK8-mK5bN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing training accuracy with validation accuracy"
      ],
      "metadata": {
        "id": "DTAxDyE5KSlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotaccwval(history, epochs)"
      ],
      "metadata": {
        "id": "lzEAOW7WKN-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing training loss with validation loss"
      ],
      "metadata": {
        "id": "ucKsxo8pKrm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotlosswval(history, epochs)"
      ],
      "metadata": {
        "id": "v477XCQ1KZy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining K-Fold cross validator and metrics"
      ],
      "metadata": {
        "id": "tKlInyO3H7w4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=4, shuffle=True) # creating the 4 fold validator\n",
        "acc_per_fold = [] # array to record the accuracy per fold\n",
        "loss_per_fold = [] # array to record the loss per fold\n",
        "over_acc = np.array # variable to keep the overall accuracy\n",
        "over_loss = np.array # variable to keep the overall loss"
      ],
      "metadata": {
        "id": "-S90s0FmIC53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold cross validation"
      ],
      "metadata": {
        "id": "n_Vb0nOgLtTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "fold_no = 1\n",
        "acc_per_fold = [] # array to record the accuracy per fold\n",
        "loss_per_fold = []\n",
        "for train, test in kfold.split(samples, labels):\n",
        "\n",
        "\n",
        "  #Define the model\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "          layers.Dense(30, input_dim=6, kernel_initializer='uniform', activation='relu', kernel_regularizer= tf.keras.regularizers.L2(0.5),bias_regularizer= tf.keras.regularizers.L2(0.9)),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Dense(60, kernel_initializer='uniform', activation='relu', kernel_constraint=tf.keras.constraints.MinMaxNorm(min_value=0.9, max_value=2, axis=0)),\n",
        "          layers.Dropout(0.2),\n",
        "          layers.Dense(10, kernel_initializer='uniform', activation='relu', kernel_constraint=tf.keras.constraints.MinMaxNorm(min_value=1.3, max_value=1.8, axis=0)),\n",
        "          layers.Dropout(0.1),\n",
        "          layers.Dense(1, kernel_initializer='uniform', activation='relu'),\n",
        "\n",
        "          \n",
        "         \n",
        "      ]\n",
        "  )\n",
        " \n",
        "  \n",
        "\n",
        "  #Compile the model\n",
        "  model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "  #print\n",
        "  print('\\n-------------------------------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no}')\n",
        "\n",
        "  # Fit data to model\n",
        "  epochs = 600\n",
        "  history = model.fit(x=samples[train], y=labels[train], batch_size=256, epochs=epochs, shuffle=True, verbose=0)\n",
        "  #metrics\n",
        "  scores = model.evaluate(x=samples[test], y=labels[test], verbose=2)\n",
        "  print('\\n')\n",
        "  print(f'Prediction score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1]*100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  plotacc(history, epochs)\n",
        "  plotloss(history,epochs)\n",
        "\n",
        "  # next fold\n",
        "  fold_no = fold_no + 1\n"
      ],
      "metadata": {
        "id": "3ED42qiYLyJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "Au5tEIjjOO_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy per fold"
      ],
      "metadata": {
        "id": "DevlWNvIORjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy for each fold : \")\n",
        "k=1\n",
        "for i in acc_per_fold:\n",
        "    l = \"%.4f\" % i\n",
        "    print('Fold ', k,'is ', l)\n",
        "    k=k+1"
      ],
      "metadata": {
        "id": "a0HaMXR_q0Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folds = range(1,5)\n",
        "plt.plot(folds, acc_per_fold, 'g', label='Accuracy')\n",
        "plt.title('Accuracy per fold')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c3kcKKUlOE-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss per fold"
      ],
      "metadata": {
        "id": "o_qmy-9DOUxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loss for each fold : \")\n",
        "k=1\n",
        "for i in loss_per_fold:\n",
        "    l = \"%.4f\" % i\n",
        "    print('Fold ', k,'is ', l)\n",
        "    k=k+1"
      ],
      "metadata": {
        "id": "jQPhO7pzq16C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folds = range(1,5)\n",
        "plt.plot(folds, loss_per_fold, 'r', label='Loss')\n",
        "plt.title('Loss per fold')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nGK3nAv1OKdQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}